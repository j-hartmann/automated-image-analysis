{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "uXvdqasFBGMp",
        "i2q6g-5FBKQm",
        "wdjhAU3_E6bc",
        "HBSB-P7Z4w8z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-hartmann/automated-image-analysis/blob/branch_s/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "uXvdqasFBGMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# install yolo\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!cd yolov5\n",
        "!pip install -r requirements.txt  # install\n",
        "!cd content"
      ],
      "metadata": {
        "id": "WR7emBIQQDuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# install IQA library\n",
        "!pip install image-quality\n",
        "import imquality.brisque as brisque"
      ],
      "metadata": {
        "id": "J1x0XwVndWP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLQlgJ2mA72b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import re\n",
        "#import distutils.dir_util\n",
        "import torch\n",
        "import skimage.measure\n",
        "import copy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import PIL.Image \n",
        "#from matplotlib.colorbar import Colorbar\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ],
      "metadata": {
        "id": "TXDsOwkcR2ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link drive (optional)"
      ],
      "metadata": {
        "id": "i2q6g-5FBKQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "id": "jV_qiXQfBN5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paths \n",
        "Path to either drive folder or local directory (GC) -> Need to configure yourself"
      ],
      "metadata": {
        "id": "unr8NgMgCjmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to image folder, e.g. \"/content/drive/My Drive/images/\" \n",
        "path_images = \"\"\n",
        "# optional: export min/max images for each category\n",
        "path_images_out_min_max = \"\"\n",
        "# path to image folder, e.g. \"/content/drive/My Drive/csvs/\"\n",
        "path_csv_out = \"\"\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "jdYni9aSdnjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Control variables\n",
        "Note: brisque and visualbalance will increase computation time drastically"
      ],
      "metadata": {
        "id": "bRTdbGm4pP1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# control variables for feature extraction\n",
        "start = 0 #@param {type:\"integer\", min:0}\n",
        "end =  50#@param {type:\"integer\", min:0}\n",
        "resize = 25 #@param {type:\"integer\"}\n",
        "bool_brisque = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "bool_visualbalance = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "yolo_extraction_bool = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "print_values = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "rescale_w = 480 #@param {type:\"integer\", min:0}\n",
        "rescale_h = 480 #@param {type:\"integer\", min:0}\n",
        "bool_save_min_max_img = False #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "metadata": {
        "id": "UWwnY1zxpOY6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "wdjhAU3_E6bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: WORK IN PROGRESS\n",
        "\n",
        "# calculate the euclidean distance between two images -> symmetrical\n",
        "def euclid_dist_symmetrical(image):\n",
        "\n",
        "  '''\n",
        "  This function:\n",
        "  0. Takes in an image\n",
        "  1. calls helper function adjust_image_shape(img) to \n",
        "  adjust the shape of a given image if necessary\n",
        "  -> when col/row uneven\n",
        "  2. slices the image horizontally by height\n",
        "  3. Calculates and returns the sum of all symmetrical points between both image slices\n",
        "  '''\n",
        "\n",
        "  # extract h,w\n",
        "  height, width, channels = image.shape\n",
        "  # exit if one of width or height are not even\n",
        "  if (height % 2 != 0) or (width% 2 != 0):\n",
        "    # adjust shape of image:\n",
        "    # subtract one col or row or both from given image if it is not even\n",
        "    # reason: sub image slice need to be of same size\n",
        "    image = adjust_image_shape(image)\n",
        "\n",
        "  # cut image vertically\n",
        "  # determine value to slice image by\n",
        "  slice_by = width // 2\n",
        "  # slice array\n",
        "  slice_1 = image[:, :slice_by]\n",
        "  slice_2 = image[:, slice_by:]\n",
        "\n",
        "  # euclidean distance of rgb tuple, symmetric\n",
        "  # reference: https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "  euclid_distance = 0\n",
        "  for index in range(len(slice_1)):\n",
        "    for index2 in range(len(slice_1[index])):\n",
        "        euclid_distance += math.sqrt((slice_1[index][index2][0] - slice_2[index][-index2][0])**2 + (slice_1[index][index2][1] - slice_2[index][-index2][1])**2 + (slice_1[index][index2][2] - slice_2[index][-index2][2])**2)\n",
        "       \n",
        "  return euclid_distance/(width*height)"
      ],
      "metadata": {
        "id": "bLj18jKSvGTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: WORK IN PROGRESS\n",
        "\n",
        "# calculate the diagonal symmetrical distance between images\n",
        "def euclid_dist_diagonal(image):\n",
        "\n",
        "  '''\n",
        "  This function:\n",
        "  0. Takes in an image\n",
        "  1. calls helper function adjust_image_shape(img) to \n",
        "  adjust the shape of a given image if necessary\n",
        "  -> when col/row uneven\n",
        "  2. slices the image horizontally by height\n",
        "  3. Calculates and returns the sum of all diagonals between both image slices\n",
        "  '''\n",
        "\n",
        "  # extract h,w\n",
        "  height, width, channels = image.shape\n",
        "  # exit if one of width or height are not even\n",
        "  if (height % 2 != 0) or (width% 2 != 0):\n",
        "    # adjust shape of image:\n",
        "    # subtract one col or row or both from given image if it is not even\n",
        "    # reason: sub image slice need to be of same size\n",
        "    image = adjust_image_shape(image)\n",
        "\n",
        "  # cut image vertically\n",
        "  # determine value to slice image by\n",
        "  slice_by = height // 2\n",
        "  # slice array\n",
        "  slice_1 = image[:slice_by, :]\n",
        "  slice_2 = image[slice_by:, :]\n",
        "\n",
        "  # euclidean distance of rgb tuple, symmetric\n",
        "  # reference: https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "  euclid_distance = 0\n",
        "  for index in range(len(slice_1)):\n",
        "    for index2 in range(len(slice_1[index])):\n",
        "        euclid_distance += math.sqrt((slice_1[index][index2][0] - slice_2[-index][-index2][0])**2 + (slice_1[index][index2][1] - slice_2[-index][-index2][1])**2 + (slice_1[index][index2][2] - slice_2[-index][-index2][2])**2)\n",
        "  \n",
        "  return euclid_distance/(width*height)"
      ],
      "metadata": {
        "id": "rK-ioAdU2NQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for euclid_dist_diagonal/symmetrical\n",
        "def adjust_image_shape(img):\n",
        "  ''' \n",
        "  This function:\n",
        "  0. takes in an image and its h,w\n",
        "  1. if h or w of slice is uneven, subtract row or col\n",
        "  2. return adjusted image\n",
        "  '''\n",
        "\n",
        "  if img.shape[0] % 2 != 0:\n",
        "    # subtract row from height\n",
        "    img = img[:-1, :]\n",
        "  if img.shape[1] % 2 != 0:\n",
        "    # subtract col from width\n",
        "    img = img[:, :-1]\n",
        "  return img"
      ],
      "metadata": {
        "id": "ADzESUSEPT48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _iter(path_imgs, path_csv_out, resize_percent, start, end, bool_brisque, bool_visualbalance, yolo_extraction_bool, print_values):\n",
        "\n",
        "  '''\n",
        "  This function:\n",
        "  0. [x] Takes in input/output paths \n",
        "  1. [x] reads input csv\n",
        "  2. [x] iterates over given image path\n",
        "  3. [x] reads images\n",
        "  4. [x] performs feature extraction\n",
        "  5. [x] merges extracted features with base file\n",
        "  6. [x] exports new file\n",
        "  7. [x] yolov5 coco inference\n",
        "  8. [x] add # image features\n",
        "  '''\n",
        "\n",
        "  # structure new df\n",
        "  df_new = pd.DataFrame(columns=[\"filename\",\n",
        "                                 \"height\",\n",
        "                                 \"width\",\n",
        "                                 \"r_mean\",\n",
        "                                 \"g_mean\",\n",
        "                                 \"b_mean\",\n",
        "                                 \"hue_avg\",\n",
        "                                 \"saturation_avg\",\n",
        "                                 \"brightness_avg\", \n",
        "                                 \"greyscale_avg\",\n",
        "                                 \"shannon_entropy\",\n",
        "                                 \"size_kB\",\n",
        "                                 \"visual_complexity_kB\",\n",
        "                                 \"visual_balance_euclid_dist_symmetrical\",\n",
        "                                 \"visual_balance_euclid_dist_diagonal\",\n",
        "                                 \"image_clarity\",\n",
        "                                 \"sharpness\",\n",
        "                                 \"brisque_IQA\",\n",
        "                                 \"warm_hues_perc\",\n",
        "                                 \"cold_hues_perc\",\n",
        "                                 \"xmin\", \n",
        "                                 \"ymin\",\n",
        "                                 \"xmax\",\n",
        "                                 \"ymax\", \n",
        "                                 \"confidence\", \n",
        "                                 \"label\"])\n",
        "  \n",
        "  # read names of given image directory into list\n",
        "  # slice into array that we want to analyze\n",
        "  names = os.listdir(path_images)[start:end]\n",
        "\n",
        "  # iterate over zipped data -> [(x1,y1,z1),...,(xn,yn,zn)]\n",
        "  for index, name in enumerate(names):\n",
        "\n",
        "        # read image as BGR\n",
        "          img = cv2.imread(path_images + name)\n",
        "\n",
        "          # since read in image differs in output val when read with PIL/cv2, choose PIL as stated in documentation\n",
        "          pil_image = PIL.Image.open(path_images + name)\n",
        "\n",
        "          # resize image\n",
        "          output = cv2.resize(img, (int(img.shape[1] * resize_percent / 100), int(img.shape[0] * resize_percent / 100)))\n",
        "\n",
        "          # brisque val\n",
        "          brisque_val = 0\n",
        "          \n",
        "          # perform brisque computation\n",
        "          if bool_brisque:\n",
        "            try:\n",
        "              brisque_val = brisque.score(output)\n",
        "            except:\n",
        "              print(\"brisque error\")\n",
        "\n",
        "            if print_values:\n",
        "              print(f\"brisque={brisque_val}\")\n",
        "\n",
        "          # sharpness\n",
        "          sharpness = cv2.Laplacian(img, cv2.CV_64F).var()\n",
        "          if print_values:\n",
        "            print(f\"sharpness={sharpness}\")\n",
        "\n",
        "          # get height and width\n",
        "          height, width, channel = img.shape\n",
        "          if print_values:\n",
        "            print(\"height, width\",height, width)\n",
        "          \n",
        "          # convert to RGB\n",
        "          img_rgb = cv2.imread(path_images + name, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          # calculate the symmetrical euclidean distance of a given image\n",
        "          # important: have to verify if this follows description from paper\n",
        "          euclid_dist_sym_bool = True\n",
        "          euclid_dist_diag_bool = True\n",
        "          if bool_visualbalance:\n",
        "    \n",
        "            try:\n",
        "              euclid_dist_sym  = euclid_dist_symmetrical(img_rgb)\n",
        "            except:\n",
        "              euclid_dist_sym_bool = False\n",
        "              print(\"error: uneven image\")\n",
        "\n",
        "            # euclid dist diagonal visual balance\n",
        "            # own idea, needs to be verified and testet if useful\n",
        "            \n",
        "            try:\n",
        "              euclid_dist_diag = euclid_dist_diagonal(img_rgb)\n",
        "            except:\n",
        "              euclid_dist_diag_bool = False\n",
        "              print(\"error: uneven image\")\n",
        "\n",
        "          # split image in RGB format into single color changels\n",
        "          r,g,b = cv2.split(img_rgb)\n",
        "          # take mean\n",
        "          r_mean = r.mean()\n",
        "          g_mean = g.mean()\n",
        "          b_mean = b.mean()\n",
        "          if print_values:\n",
        "            print(f\"r={r_mean}\\nb={g_mean}\\nb={b_mean}\")\n",
        "          \n",
        "          # convert to HSV-map\n",
        "          img_hsv = cv2.imread(path_images + name, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "          # average of values\n",
        "          hue = img_hsv[0].mean()\n",
        "          if print_values:\n",
        "            print(f\"hue mean={hue}\")\n",
        "          saturation = img_hsv[1].mean()\n",
        "          if print_values:\n",
        "            print(f\"saturation mean={saturation}\")\n",
        "          brightness = img_hsv[2].mean()\n",
        "          if print_values:\n",
        "            print(f\"brightness mean={brightness}\")\n",
        "\n",
        "          # calculate proportion of warm hues\n",
        "          hues = img_hsv[0]\n",
        "          if print_values:\n",
        "            print(f\"hues={hues}\")\n",
        "          # flatten hue values\n",
        "          hues_flattened = [item for sublist in hues for item in sublist]\n",
        "          # filter warm hues\n",
        "          warm_hues = [item for item in hues_flattened if item >= 30 and item <= 110]\n",
        "          cold_hues = [item for item in hues_flattened if item < 30 or item > 110]\n",
        "          if print_values:\n",
        "            print(f\"warm hues={warm_hues}\")\n",
        "            print(f\"cold hues={cold_hues}\")\n",
        "\n",
        "          # percentage of image that is of warm hue\n",
        "          warm_hues_perc = len(warm_hues) / len(hues_flattened)\n",
        "          if print_values:\n",
        "            print(f\"warm hues perc={warm_hues_perc}\")\n",
        "          cold_hues_perc = len(cold_hues) / len(hues_flattened)\n",
        "          if print_values:\n",
        "            print(f\"cold_hues_perc={cold_hues_perc}\")\n",
        "\n",
        "          # calculate image clarity\n",
        "          # define scaler\n",
        "          scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "          # normalize brightness to [0-1]\n",
        "          normalize_brightness = scaler.fit_transform(img_hsv[2])\n",
        "          if print_values:\n",
        "            print(f\"normalize_brightness={normalize_brightness}\")\n",
        "\n",
        "          # flatten nested list\n",
        "          brightness_flattened = [item for sublist in normalize_brightness for item in sublist]\n",
        "          if print_values:\n",
        "            print(f\"flattened={brightness_flattened}\")\n",
        "\n",
        "          # count bright values -> [0,1] as described in paper\n",
        "          # https://pubsonline.informs.org/doi/suppl/10.1287/mnsc.2021.4175/suppl_file/mnsc.2021.4175.sm1.pdf\n",
        "          bright_values = [item for item in brightness_flattened if item >= 0.7]\n",
        "\n",
        "          # image clarity\n",
        "          image_clarity = len(bright_values)/len(brightness_flattened)\n",
        "          if print_values:\n",
        "            print(f\"image_clarity={image_clarity}\")\n",
        "\n",
        "          # convert to grayscale\n",
        "          img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "          # calculate contrast of image\n",
        "          # we choose RMS contrast, which is the SD of a gray image\n",
        "          RMS_contrast = img_grey.std()\n",
        "          if print_values:\n",
        "            print(f\"RMS_contrast={RMS_contrast}\")\n",
        "\n",
        "          # average of grayscale\n",
        "          avg_grey = np.average(img_grey)\n",
        "          if print_values:\n",
        "            print(f\"avg_gray={avg_grey}\")\n",
        "          \n",
        "          # average RGB values in this image\n",
        "          # [[[]]] -> []\n",
        "          avg_rgb_values = np.average(np.average(img_rgb, axis=0), axis=0)\n",
        "          if print_values:\n",
        "            print(f\"avg_rgb_values={avg_rgb_values}\")\n",
        "\n",
        "\n",
        "          # object detection inference yolov5 (choose model earlier)\n",
        "          predictions = []\n",
        "          if yolo_extraction_bool:\n",
        "            predictions = model(img).pandas().xyxy[0]\n",
        "            if print_values:\n",
        "              print(f\"predictions={predictions}\")\n",
        "\n",
        "            # number of detected objects -> one xmin (arbitrary value) for each found bb\n",
        "            numb_objects = len(predictions[\"xmin\"])\n",
        "            if print_values:\n",
        "              print(f\"numb_objects={numb_objects}\")        \n",
        "\n",
        "          # file size in kB -> file read in as # in bit\n",
        "          file_size_kB = int(os.path.getsize(path_imgs + name) /(1024 * 8))\n",
        "          if print_values:\n",
        "            print(f\"file size in bit={file_size_kB}\")\n",
        "\n",
        "          # visual complexity kB\n",
        "          visual_complexity_kB = file_size_kB / (width*height)\n",
        "          if print_values:\n",
        "            print(f\"visual complexity kB={visual_complexity_kB}\")\n",
        "\n",
        "          # Shannon-Entropy\n",
        "          shannon_entropy = skimage.measure.shannon_entropy(img)\n",
        "          if print_values:\n",
        "            print(f\"shannon-entropy={shannon_entropy}\")\n",
        "\n",
        "          # write values\"\n",
        "          df_new.at[index, \"filename\"] = name\n",
        "          df_new.at[index, \"hue_avg\"] = hue\n",
        "          df_new.at[index, \"saturation_avg\"] = saturation\n",
        "          df_new.at[index, \"brightness_avg\"] = brightness\n",
        "          df_new.at[index, \"greyscale_avg\"] = avg_grey\n",
        "          df_new.at[index, \"width\"] = width\n",
        "          df_new.at[index, \"height\"] = height\n",
        "          df_new.at[index, \"shannon_entropy\"] = shannon_entropy\n",
        "          df_new.at[index, \"visual_complexity_kB\"] = visual_complexity_kB\n",
        "          df_new.at[index, \"size_kB\"] = file_size_kB\n",
        "          # image clarity\n",
        "          df_new.at[index, \"image_clarity\"] = image_clarity\n",
        "\n",
        "          # warm/cold hues perc\n",
        "          df_new.at[index, \"warm_hues_perc\"] = warm_hues_perc\n",
        "          df_new.at[index, \"cold_hues_perc\"] = cold_hues_perc\n",
        "\n",
        "          # means of colors\n",
        "          df_new.at[index, \"r_mean\"] = r_mean\n",
        "          df_new.at[index, \"g_mean\"] = g_mean\n",
        "          df_new.at[index, \"b_mean\"] = b_mean\n",
        "\n",
        "          # sharpness\n",
        "          df_new.at[index, \"sharpness\"] = sharpness\n",
        "\n",
        "          # RMS contrast\n",
        "          df_new.at[index, \"RMS_contrast\"] = RMS_contrast\n",
        "\n",
        "          # brisq val\n",
        "          if bool_brisque:\n",
        "            df_new.at[index, \"brisque_IQA\"] = brisque_val\n",
        "          else:\n",
        "            df_new.at[index, \"brisque_IQA\"] = \"\"\n",
        "\n",
        "          # euclidean average distance between pixels across the \n",
        "          # symmetrical (split image) vertical line\n",
        "          if euclid_dist_sym_bool and bool_visualbalance:\n",
        "            df_new.at[index, \"visual_balance_euclid_dist_symmetrical\"] = euclid_dist_sym\n",
        "          \n",
        "          else:\n",
        "            df_new.at[index, \"visual_balance_euclid_dist_symmetrical\"] = \"\"\n",
        "          \n",
        "          # euclidean average distance of diagonals\n",
        "          # if even image\n",
        "          if euclid_dist_diag_bool and bool_visualbalance:\n",
        "            df_new.at[index, \"visual_balance_euclid_dist_diagonal\"] = euclid_dist_diag\n",
        "          \n",
        "          else:\n",
        "              df_new.at[index, \"visual_balance_euclid_dist_diagonal\"] = \"\"\n",
        "            \n",
        "          # if predicitons is not empty\n",
        "          if yolo_extraction_bool == True:\n",
        "            #if predictions.empty() == False:\n",
        "              # write most predictions in df\n",
        "              df_new.at[index,\"xmin\"] = predictions[\"xmin\"].to_list()\n",
        "              df_new.at[index,\"ymin\"] = predictions[\"ymin\"].to_list()\n",
        "              df_new.at[index,\"xmax\"] = predictions[\"xmax\"].to_list()\n",
        "              df_new.at[index,\"ymax\"] = predictions[\"ymax\"].to_list()\n",
        "              df_new.at[index,\"confidence\"] = predictions[\"confidence\"].to_list()\n",
        "              df_new.at[index,\"label\"] = predictions[\"name\"].to_list()\n",
        "          \n",
        "  # drop unnamed if existent\n",
        "  if df_new.columns[0] == \"Unnamed: 0\":\n",
        "    df_new = df_new.drop(\"Unnamed: 0\", axis=1)\n",
        "\n",
        "  # export merged files\n",
        "  df_new.to_csv(path_csv_out + f\"Pipeline_CV_features_start_{start}_end_{end}.csv\")"
      ],
      "metadata": {
        "id": "Ybdm6WvEEMOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read full csv in\n",
        "# with filename\n",
        "def investigate(rescale_width, rescale_height, filepath, img_out):\n",
        "  \n",
        "  # read previously compute feature file\n",
        "  df = pd.read_csv(filepath)\n",
        "  # store names in list\n",
        "  names = df[\"filename\"].to_list()\n",
        "  # drop non-numeric values\n",
        "  if bool_visualbalance:\n",
        "    df = df.drop([\"Unnamed: 0\",\"filename\", \"ymax\", \"ymin\", \"xmax\", \"xmin\", \"confidence\", \"label\"], axis=1)\n",
        "  else:\n",
        "    df = df.drop([\"Unnamed: 0\",\"filename\", \"ymax\", \"ymin\", \"xmax\", \"xmin\",\"visual_balance_euclid_dist_symmetrical\", \"visual_balance_euclid_dist_diagonal\", \"confidence\", \"label\"], axis=1)\n",
        "  if bool_brisque == False:\n",
        "    df = df.drop(\"brisque_IQA\", axis=1)\n",
        "\n",
        "\n",
        "  # zip indices of min, max with columns in df2\n",
        "  # iterate over them\n",
        "  for indexmin, indexmax, col in zip(df.idxmin(), df.idxmax(), df.columns):\n",
        "    min_name = names[int(indexmin)]\n",
        "    max_name = names[int(indexmax)]\n",
        "\n",
        "    # read in min image\n",
        "    imagemin = cv2.imread(path_images + min_name)\n",
        "    # resize min image to default value\n",
        "    image_min_scaled = cv2.resize(imagemin, (rescale_width, rescale_height))\n",
        "    # read in max image\n",
        "    imagemax = cv2.imread(path_images + max_name)\n",
        "    # rescale max image to default value\n",
        "    image_max_scaled = cv2.resize(imagemax, (rescale_width, rescale_height))\n",
        "\n",
        "    min_val = df.at[int(indexmin), col]\n",
        "    max_val = df.at[int(indexmax), col]\n",
        "\n",
        "    double_window =  np.concatenate((image_min_scaled, image_max_scaled), axis=1)\n",
        "    print(f\"\\nFeature:  {col}\\nLeft(min) value: {min_val} image: {min_name}\")\n",
        "    print(f\"Right(max) value: {max_val} image: {max_name}\")\n",
        "    cv2_imshow(double_window)\n",
        "\n",
        "    # if save min/max selected\n",
        "    if bool_save_min_max_img:\n",
        "      # save min\n",
        "      cv2.imwrite(img_out + col + \"_min_\" + min_name, imagemin)\n",
        "      # save max\n",
        "      cv2.imwrite(img_out + col + \"_max_\" + max_name, imagemax)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4TgUI0fOWfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze images"
      ],
      "metadata": {
        "id": "HBSB-P7Z4w8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# time function call\n",
        "starttime = time.time()\n",
        "# function call\n",
        "_iter(path_imgs=path_images,\n",
        "      path_csv_out=path_csv_out,\n",
        "      resize_percent = resize,\n",
        "      start=start,\n",
        "      end=end,\n",
        "      bool_brisque=bool_brisque,\n",
        "      bool_visualbalance=bool_visualbalance,\n",
        "      yolo_extraction_bool = yolo_extraction_bool,\n",
        "      print_values=print_values)\n",
        "\n",
        "endtime = time.time()\n",
        "print(f\"Elapsed time for computing: {endtime-starttime}\")"
      ],
      "metadata": {
        "id": "uW7GKyIWV550"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect extracted features (open to see outputs)"
      ],
      "metadata": {
        "id": "4V2N8k0kuD2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read extracted feature file\n",
        "# drop cols with NaN values\n",
        "df = pd.read_csv(path_csv_out + f\"Pipeline_CV_features_start_{start}_end_{end}.csv\")\n",
        "\n",
        "# drop cols containing NaNs\n",
        "if bool_brisque == False:\n",
        "  df = df.drop(\"brisque_IQA\", axis=1)\n",
        "if bool_visualbalance == False:\n",
        "  df = df.drop([\"visual_balance_euclid_dist_symmetrical\",\"visual_balance_euclid_dist_diagonal\"], axis=1)\n",
        "if yolo_extraction_bool == False:\n",
        "  df = df.drop([\"ymax\",\"ymin\", \"xmax\", \"xmin\", \"confidence\", \"label\"], axis=1)\n",
        "if df.columns[0] == \"Unnamed: 0\":\n",
        "  df = df.drop(\"Unnamed: 0\", axis=1)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "_mdStIzWu_VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigate max/min feature values (open to see outputs)\n",
        "Note: Since images might be too small or too big, they will be resized to a default value of 300."
      ],
      "metadata": {
        "id": "OYXFAK-cBXgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# investigates last file containing extracted features\n",
        "investigate(rescale_width=rescale_w, rescale_height=rescale_h, filepath = path_csv_out + f\"Pipeline_CV_features_start_{start}_end_{end}.csv\", img_out=path_images_out_min_max)"
      ],
      "metadata": {
        "id": "8qgeWZaWGNmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}